# CUBSAT segmentation

Модель Ultralytics YOLOv11 для instance-сегментации составных частей космических аппаратов типа CUBSAT.

## Описание проекта

Данный проект решает задачу instance-сегментации составных частей космических аппаратов типа CUBSAT.
Обученная модель подходит для работы с изображениями в градациях серого (Monochrome), преобразованными в RGB для расширения каналов тензора входного изображения.
Само изображение при этом остается черно-белым.
Возможна интеграция модели в графические или консольные приложения Windows, написанные на Python.

## Структура проекта

### 'root/'
Корневая директория проекта
 - inference/ : Директория с моделью и данными для инференса
 - Model_cfg/ : Директория с конфигурационными файлами модели
 - scripts/ : Директория со скриптами для предобработки данных
 - src/ : Основная директория для исходного кода
 - requirements.txt': Список требуемых модулей
 - README.md': Документация

### 'inference/'
Директория с моделью и данными для инференса
 - 'output/': Директория для сохранения изображений с отрисованными полигонами после инференса
 - 'yolo11n-seg_final.pt': Модель YOLOv11 для инференса
 - '.jpg': Тестовые изображения для проверки качества работы модели

### 'Model_cfg/'
Директория с конфигурационными файлами модели
 - 'model_cfg.json': .json файл с гиперпараметрами модели для обучения
 - 'yolo11n-seg.pt': Модель YOLOv11, предобученная на датасете COCO для задачи сегментации
 - 'yolo11n-seg.yaml': Конфигурационный файл для создания модели YOLOv11 с нуля
 - 'yolo11n-seg_labeling.pt': Fine-tuned модель YOLOv11, дообученная под задачу instance-segmentation составных частей космических аппаратов типа CUBSAT

### 'scripts/'
Директория со скриптами для предобработки данных и тестирования работы модели
 - 'convert_to_rgb.py': Скрипт, конвертирующий моноканальные monochrome изображения в черно-белые изображения RGB для подачи на вход модели YOLOv11
 - 'test_labeling.py': Скрипт, отрисовывающий полигоны объектов из аннотации к изображению на самом изображении

### 'src/'
Основная директория для исходного кода
 - 'tests': Директория с файлами для тестирования кода
 - 'main.py': Точка входа в приложение (основной скрипт для запуска)
 - 'utils.py': Модуль, содержащий пользовательские классы, необходимые для работы

## Установка зависимостей
В консоли IDE программы перейдите в корневую папку проекта и активируйте виртуальную среду, если она еще не была активирована.
Введите команду pip install -r requirements.txt для установки модулей из файла requirements.txt

## Структура данных
Для работы с моделью Ultralytics YOLOv11 необходим
датасет следующего формата:

### 'root/'
Корневая директория датасета
 - images/ : папка с изображениями
 - labels/ : папка с аннотациями
 - dataset.yaml: файл конфигурации датасета в формате .yaml

### 'images/'
Папка с изображениями
 - train/ : папка с изображениями для обучения модели
 - val/ : папка с изображениями для валидации
 - test/ : (опционально) папка с изображениями для проверки качества обученной модели

### 'labels/'
Папка с аннотациями
 - train/ : папка с аннотациями для обучения модели
 - val/ : папка с аннотациями для валидации
 - test/ : (опционально) папка с аннотациями для проверки качества обученной модели

### 'dataset.yaml'
Конфигурационный файл датасета для модели Ultralytics YOLOv11 в формате .yaml.
Файл имеет следующую структуру:
 - path: полный путь до корневой папки с датасетом
 - train: images/train
 - val: images/val
 - nc: количество классов, используемых в датасете
 - names: список с именами классов

## Структура конфигурационных файлов модели
В проекте используются два конфигурационных файла модели, находящиеся в папке Model_cfg:
 - model_cfg.json - файл с гиперпараметрами для обучения модели
 - yolo11n-seg.yaml - конфигурационный файл, используемый для созданияя модели "с нуля" (можно скачать из репозитория ultralytics на github)

### 'model_cfg.json'
Ниже будет представлено описание ключей и значений .json словаря в формате "ключ: тип данных (диапазон значений) - описание"
 - "epochs": int(> 0) - количество эпох обучения модели
 - "imgsz": int(> 0) - размер квадратных изображений, используемых для обучения
 - "batch": int(> 0) - размер батча
 - "lr0": float(> 0) - начальный шаг обучения
 - "patience": int(> 0) - количество эпох без улучшений, после которых осуществляется ранняя остановка обучения
 - "device": int or str(0 or "cpu") - устройство, на котором будет осуществляться обучение (0, если доступно обучение на GPU, иначе "cpu")
 - "optimizer": str("Adam" или другие) - оптимизатор
 - "freeze_layers": int(>= 0) - количество "замораживаемых" в процессе обучения слоев

## Работа с проектом
Для запуска основного кода проекта используется файл main.py.
Для работы с моделью создается экземпляр класса Pipeline из файла utils.py.
В этот экземпляр передаются необходимые атрибуты, которые были инициализированы в файле main.py ранее.
Описание необходимых атрибутов для класса Pipeline и их типов данных представлено в описании класса.
После инициализации объекта Pipeline можно использовать методы класса Pipeline для работы:
 - .fine_tune_for_labeling(model_output_path) для дообучения предобученной модели и сохранению ее по пути model_output_path
 - .create_json_annotations(test_images_dir=output_path_img, annotations_output_dir=output_path_labels) для создания аннотаций к изображениям в директории
output_path_img и сохранения аннотаций в директории output_path_labels
 - .convert_labelme_to_yolo(labelme_annotations_path=labelme_input_labels_path, yolo_annotations_path=yolo_convert_labels_path) для конвертации аннотаций из формата LabelMe в формат YOLO

Для проверки работоспособности модели используется скрипт 'run_inference.py' из папки 'scripts/'.
Необходимо изменить пути в переменных IMAGE_PATH, OUTPUT_PATH и MODEL_PATH согласно абсолютным путям к файлу модели, изображению для инференса и файлу в выходной директории, после чего запустить скрипт.